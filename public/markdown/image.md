## 개요

이 모델은 부스트캠프 AI Tech의 마스크 착용 상태 분류 대회를 통해 얻어진 결과물로 사진에 나타난 인물이 마스크를 착용했는지 여부를 판단할 수 있습니다. 본 페이지에서 웹캠을 사용해 사진을 찍거나 이미지를 업로드하면 해당 이미지 데이터가 서버로 전송되어 서버의 제가 생성한 딥러닝 모델을 통해 얻어진 결과를 바로 확인하실 수 있습니다.

### 소스코드

<https://github.com/ysb06/boostcamp-p1-image>


## 대회 요약

본 대회의 목적은 사람 얼굴 이미지로부터 해당 인물이 마스크를 썼는지, 제대로 착용하였는지, 해당 사람의 성별은 어떻게 되는지, 그리고 나이대는 어떻게 되는지 여부를 분류하는 것이었습니다.

사용된 데이터는 총 4500명의 아시아인 사진들을 사용하였으며 해당 인원의 60%는 학습 데이터셋 그리고 20%는 Public 테스트 데이터셋, 나머지 20%는 Private 테스트 데이터셋으로 사용되었습니다. 그리고 각 사람마다 5장의 마스크 착용 샷, 마스크를 이상하게 착용한 샷 1장, 그리고 미착용 샷 1장, 총 7장의 사진이 있습니다.

<div class="md-image-group"> 
<p><img src="/image/mask-md-01.png"></p>
<p>그림1. 대회 이미지 예시</p>
</div>

대회에서는 이러한 이미지들을 마스크 상태, 성별, 나이에 따른 18개의 클래스로 나누어야 했으며 해당 클래스들에 대한 자세한 사항은 아래와 같습니다.

<div class="md-image-group"> 
<p><img src="/image/mask-md-02.png"></p>
<p>그림2. 클래스 상세</p>
</div>

## 데이터 분석 (EDA)

데이터 분류 전 데이터의 형태를 확인하기 위해 EDA를 수행하였습니다. 먼저, 레이블 데이터를 주로 살펴보았고 이미지들에 대한 분석은 대회 시간 관계 상 이미지 처리 과정에서 문제가 생길 경우 추가로 수행하기로 하고 특별히 진행하지 않았습니다.

### 수행 내용

<div class="md-image-group"> 
<p><img src="/image/mask-md-03.png"></p>
<p>그림3. 기본 데이터 요약</p>
</div>

<div class="md-image-group"> 
<p><img src="/image/mask-md-04.png"></p>
<p>그림4. Feature 별 분포 그래프</p>
</div>

위 그림에서 보이듯 데이터 Feature 별로 데이터가 불균형한 것을 확인할 수 있으며 나이 부분에서 데이터 편중이 심각한 것을 확인할 수 있었습니다. 특히, 60대 이상의 경우 나이가 60 외에 60보다 큰 데이터는 없었다는 점이 눈에 띄었습니다. 결론적으로 이와 같은 데이터 불균형 문제를 해결하는 것이 모델의 일반화 성능을 높이는 데 중요한 역할을 할 것으로 예측했습니다.

그리고 사진들을 직접 확인도 했고 다른 캠퍼 분들도 지적한 사항이지만 레이블이 잘못된 데이터도 있었습니다. 예를 들어, 누가 봐도 여자사진이지만 레이블은 남자로 되어 있다든가, 마스크를 쓴 사진과 마스크를 잘못 쓴 사진의 레이블이 다르다든가 하는 문제들이 있었고 이런 부분은 직접 데이터를 수정하여 해결하기로 했습니다.


## 모델 개발 과정

### 모델 분할

레이블 데이터 EDA를 하면서 떠오른 생각은 대회에서는 18개 클래스로 분류할 것으로 요구하였지만 실제로는 각기 다른 3개의 과업을 수행하라는 것과 같다는 것이었습니다. 하나의 딥러닝 모델로 3개의 서로 다른 과업을 수행하기 위해서는 모델의 크기가 커져야 하는 데, 지나치게 큰 모델은 생성하는 데 있어 더 많은 데이터와 학습시간을 요구하고 과적합의 위험성도 커진다는 문제점이 있습니다.

따라서, 적정 수준으로 과업을 나누고 모델을 작게 유지할 필요가 있다고 생각하여 대회를 위한 다음과 같이 추론 모델을 설계했었습니다.

<div class="md-image-group"> 
<p><img src="/image/mask-md-05.png"></p>
<p>그림5. 초기 모델 설계</p>
</div>

다만, 모델 개발은 진행하면서 무조건 모델을 많이 만드는 것은 정답은 아니었으며 최종 모델에서는 마스크 부분에서 마스크 착용과 잘 못 착용한 모델을 하나의 모델을 통해 처리하도록 합쳤을 때 성능이 훨씬 더 잘 나오는 것으로 나타났습니다. (F1-Score 0.1402 → 0.5490, 이 결과는 EffcientNet-B0에서 EffcientNet-B7으로 모델을 수정한 영향도 포함)

### 데이터셋 설계 및 데이터 증강(Augmentation)

대회 중에 여러 과업에 따라 요구하는 레이블이 다를 수 있으므로 쉽게 레이블을 생성하는 코드를 추가하여 확장할 수 있도록 코드 구조를 고민하였고, 이에 맞게 데이터를 정의하고 모델에 따라 다른 데이터를 제공할 수 있는 데이터셋 코드를 작성하였습니다.

<div class="md-image-group"> 
<p><img src="/image/mask-md-06.png"></p>
<p>그림6. 데이터 기본 구조</p>
</div>

그리고 데이터 불균형 문제를 해결하기 위해 Feature 별로 부족한 데이터의 경우 Oversampling을 통해 균형을 맞추어 주었습니다. 이것을 구현할 때, 단순히 데이터를 증가시키는 것 보다 레이블 종류가 변경되면 그에 맞추어 데이터를 증가시키는 것으로 특별히 코드를 작성하였습니다.

또한, 데이터 불균형 문제와 함께 일반화 성능을 높이고자 데이터 증강을 수행하였습니다. 데이터 증강은 Albumentation 라이브러리를 사용하여 구현하였으며, 데이터가 모델에 투입되는 시점에 증강 될 수 있게 했습니다. 여기에 사용되는 이미지는 주로 사용자 정면을 찍은 사진임을 고려하여 다음과 같은 증강 기법을 사용했습니다.
- SmallestMaxSize (이미지 크기 조정)
- CenterCrop (가장자리의 배경 부분 제거)
- HorizontalFlip (p=0.5 좌우 대칭)
- ShiftScaleRotate (p=0.5, rotate_limit=15 이미지 회전)
- HueSaturationValue (hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5 색조 조정)
- RandomBrightnessContrast (brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5 밝기 조정)
- GaussNoise (p=0.5)
- Normalize

이와 같은 데이터 증강 기법은 위에서 언급한 Oversampling과 결합되어 Oversampling의 단점인 같은 데이터가 학습에 사용되어 과적합 되는 것을 어느정도 방지할 수 있었습니다.

### Backbone 모델 선정 및 레이어 Freeze

이미지 분류를 위한 기본 Backbone 모델을 선정하기 위해 VGG, ResNet, DenseNet 등 다양한 모델을 공부하고 검토하였습니다. 그중에서 2019년 발표된 EffcientNet에 주목하였으며 다른 기존 모델에 비해 획기적으로 좋은 성능을 보이는 것을 보고 EfficientNet 중 가장 큰 모델인 EffcientNet-B7을 선정하였습니다. 가장 큰 모델은 선택한 이유는 특별한 이유는 아니고 대회에서 주어진 컴퓨팅 자원이 넉넉하게 주어졌기 때문에(V-100) 이를 최대한으로 활용할 수 있을 것으로 예상했기 때문이었습니다.

이후, EffcientNet-B7 보다 작은 B5, B0도 테스트 했지만 성능 향상은 없었고 대신 다른 팀원과 정보를 공유하면서 ResNext 모델이 성능이 더 낫다는 정보에 따라 이를 적용하였습니다. 사용된 모델은 ResNext-101 (Cardinality = 32, Dimension = 8)이며 이전의 EffcientNet에 비해 F1-Score 기준 0.5099 → 0.6951로 큰 성능 향상을 이룰 수 있었습니다.

추가로, Pretrained Model 모델을 Backbone 모델로 활용할 때, 마지막 일부분의 레이어를 제외하고 나머지 레이어를 Freeze 시켜서 학습을 수행하였습니다. 이렇게 할 경우, pretrained 과정에서 얻어진 최적의 필터를 사용할 수 있다는 점에서 장점을 가집니다. 실제로 모든 레이어를 Freeze 하지 않고 학습을 수행할 경우 성능은 오히려 떨어지는 것을 확인 할 수 있었습니다.

<div class="md-image-group"> 
<p><img src="/image/mask-md-07.png" width=320></p>
<p>그림7. 모든 레이어 unfreeze 후 Training Loss 변화</p>
</div>

### Loss, Optimizer 그리고 LR Scheduler

Loss 함수의 경우 일반적으로 분류에 사용되는 Cross Entropy Loss(CE) 대신 Focal Loss를 사용하였습니다. 다른 팀원들의 경우 이 Loss 사용을 통해 성능을 향상시켰으며, 저도 해당 Loss 함수로 변경한 후에 이전에 비해 높은 점수를 얻을 수 있었습니다. 다만, Loss 함수만 바꾸었을 때, 실제로 성능 향상이 얼마나 이루어지는지 테스트는 수행하지 않아 정확한 영향은 파악할 수 없었습니다.

Optimizer의 경우 일반적으로 많이 사용되며 특히 이미지 분류에서 좋은 성능을 내는 Adam을 사용했습니다. 짧은 대회 기간 상 다른 Optimzer를 테스트 해보지는 못했습니다.

그리고, 학습 Step 수에 따라 Learning Rate(LR)를 변화시켜주는 Scheduler를 사용했으며, 그 중에서도 주기적으로 LR을 크게 변화시켜 Local Minimum에서 벗어나게 해주는 CosineAnnealingLR을 사용하여 학습성능을 높이고자 하였습니다.


## 결과

대회 참여 결과는 최종적으로 ResNext 기반 18개 클래스로 분류하는 단일모델이 Accuracy 75.0476%, F1 Score 0.6951 성능을 보여주었습니다. 결국 총 순위 224명 중 145위로 좋은 성적은 내지 못했습니다. 원래 계획했던 여러 과업으로 나누어 합치는 구조의 모델은 성공하지 못했습니다.

### 원인

대회가 끝나고 나서 최근 코드 검토 후에 검증(Validation) 과정의 데이터 증강이 잘못 적용되어 있었다는 사실을 발견했습니다. 위에서 언급한 Training 과정에서 데이터 증강 기술의 경우 검증 과정에서는 확률적으로 적용되는 변형 코드를 빼야 했는데 실수로 빼지 말아야 할 SmallestMaxSize 코드도 검증 과정에서 빠져 버린 것이었습니다.

즉, 학습과정에서는 정해진 크기로 이미지를 줄여서 학습하지만 검증 과정에서는 원래 이미지 크기로 테스트를 진행하여 검증을 제대로 하지 못했던 것이었습니다. 이것은 Leader Board 채점을 위한 추론 단계에서도 그대로 적용되 낮은 점수로 이어졌습니다.

실제로, 당시 마스크 인식 부분에 대한 모델 학습 시 검증단계에서 정확도가 93% 였던 모델이 해당 버그를 수정하고 최근에 다시 학습한 결과 99%까지 개선된 것을 확인할 수 있었습니다.

대회 기간이 짧은데다 예상했던 대로 결과가 나오지 않았을 때 너무 당황하여 차분히 원인 분석을 할 여유를 가지지 못해서 실수도 많이 하고 이후 수행한 작업들이 좋은 결과를 얻지 못한 것 같습니다.

### 얻은 점

이런저런 일들이 많았고 성공적으로 대회를 수행하지는 못했지만 이 과정을 통해 여러 이미지 분류 모델 및 그 학습 방법, 데이터셋 개발 방법, 데이터 증강 등 기본적으로 딥러닝에 사용되는 다양한 기술 들을 체험해보고 실제 사용가능한 코드를 작성해보고 프로그램 구조를 설계해 볼 수 있었다는 점에서 큰 의미를 가진다고 생각합니다.

이번에는 단순 이미지 분류 과업만 수행해 보았지만 추후 객체 인식(Object Detection)과 같은 좀 더 심화된 과업에 대해서도 도전해 볼 계획입니다.